{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b9e902",
   "metadata": {},
   "source": [
    "## 1. Configuração e Carregamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7992bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler # <-- Importante: para normalizar os scores\n",
    "\n",
    "# --- Configurações ---\n",
    "K = 3 # O número de recomendações final\n",
    "K_SVD = 2 # O número de fatores latentes (igual ao 04_CF)\n",
    "\n",
    "# Pesos do Híbrido:\n",
    "# Daremos mais peso ao CF (ML Puro) por ser mais \"inteligente\"\n",
    "W_CF = 0.6  # 60%\n",
    "W_CB = 0.4  # 40%\n",
    "\n",
    "print(\"Bibliotecas carregadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a1163",
   "metadata": {},
   "source": [
    "## 2. Carregar Todos os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b6b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ficheiros MVP carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_provincias_feat = pd.read_csv('../data/provincia_features_MVP.csv', index_col='Provincia')\n",
    "    df_users_feat = pd.read_csv('../data/user_features_MVP.csv', index_col='user_id')\n",
    "    df_interactions = pd.read_csv('../data/user_interactions_MVP.csv')\n",
    "    print(\"Ficheiros MVP carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Ficheiros MVP não encontrados na pasta /data/!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10901ab",
   "metadata": {},
   "source": [
    "## 3. Recriar o Motor 1: Content-Based (CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdffb7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A executar: Motor 1 (Content-Based) ---\n",
      "Scores do Content-Based (CB) calculados e normalizados.\n",
      "Provincia  Luanda  Benguela  Huíla  Namibe  Malanje  Cabinda  Huambo  \\\n",
      "user_id                                                                \n",
      "1            1.00      1.00   0.00    0.00     0.00     0.00    0.00   \n",
      "2            0.00      0.00   0.85    1.00     0.74     0.12    0.53   \n",
      "3            0.55      0.32   1.00    0.57     1.00     1.00    1.00   \n",
      "\n",
      "Provincia  Cuando Cubango  \n",
      "user_id                    \n",
      "1                    0.00  \n",
      "2                    1.00  \n",
      "3                    0.84  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- A executar: Motor 1 (Content-Based) ---\")\n",
    "# 1. Preparar features (igual ao 03_CB)\n",
    "features_das_provincias = df_provincias_feat[['impacto_ambiental', 'feat_cultura', 'feat_praia', 'feat_aventura', 'feat_natureza']]\n",
    "features_dos_utilizadores = df_users_feat[['pref_sustentavel', 'pref_cultura', 'pref_praia', 'pref_aventura', 'pref_natureza']]\n",
    "features_dos_utilizadores.columns = features_das_provincias.columns # Alinhar nomes\n",
    "\n",
    "# 2. Calcular scores CB\n",
    "matriz_similaridade = cosine_similarity(\n",
    "    features_dos_utilizadores.values, \n",
    "    features_das_provincias.values\n",
    ")\n",
    "df_scores_cb = pd.DataFrame(\n",
    "    matriz_similaridade,\n",
    "    index=features_dos_utilizadores.index,\n",
    "    columns=features_das_provincias.index\n",
    ")\n",
    "\n",
    "# 3. Normalizar os scores CB (0 a 1)\n",
    "# O Cosine Similarity já está numa escala de 0-1, mas o MinMaxScaler garante.\n",
    "scaler_cb = MinMaxScaler()\n",
    "scores_cb_normalized = scaler_cb.fit_transform(df_scores_cb)\n",
    "df_scores_cb_norm = pd.DataFrame(scores_cb_normalized, index=df_scores_cb.index, columns=df_scores_cb.columns)\n",
    "\n",
    "print(\"Scores do Content-Based (CB) calculados e normalizados.\")\n",
    "print(df_scores_cb_norm.round(2).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c3032",
   "metadata": {},
   "source": [
    "## 4. Recriar o Motor 2: Collaborative Filtering (CF / SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c4323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A executar: Motor 2 (Collaborative Filtering) ---\n",
      "Scores do Collaborative Filtering (CF) calculados e normalizados.\n",
      "provincia_visitada  Benguela  Cuando Cubango  Huambo  Huíla  Luanda  Malanje\n",
      "user_id                                                                     \n",
      "1                       1.00             0.0     0.0    1.0    1.00      0.0\n",
      "2                       0.03             1.0     1.0    0.0    0.03      1.0\n",
      "3                       0.00             0.8     0.8    0.0    0.00      0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- A executar: Motor 2 (Collaborative Filtering) ---\")\n",
    "# 1. Criar a Matriz (igual ao 04_CF)\n",
    "df_matrix = df_interactions.pivot(\n",
    "    index='user_id',\n",
    "    columns='provincia_visitada',\n",
    "    values='rating'\n",
    ").fillna(0)\n",
    "matrix_esparsa = csr_matrix(df_matrix.values)\n",
    "\n",
    "# 2. Treinar o SVD\n",
    "model = TruncatedSVD(n_components=K_SVD, random_state=42)\n",
    "model.fit(matrix_esparsa)\n",
    "\n",
    "# 3. Gerar Previsões (matriz reconstruída)\n",
    "factores_user = model.transform(matrix_esparsa)\n",
    "factores_item = model.components_\n",
    "matriz_reconstruida_scores = np.dot(factores_user, factores_item)\n",
    "\n",
    "df_previsoes_svd = pd.DataFrame(\n",
    "    matriz_reconstruida_scores, \n",
    "    index=df_matrix.index, \n",
    "    columns=df_matrix.columns\n",
    ")\n",
    "\n",
    "# 4. Normalizar os scores CF (CRUCIAL!)\n",
    "# Os scores do SVD (ex: 0.49, 5.0, -0.0) não estão na escala 0-1.\n",
    "scaler_cf = MinMaxScaler()\n",
    "scores_cf_normalized = scaler_cf.fit_transform(df_previsoes_svd)\n",
    "df_scores_cf_norm = pd.DataFrame(scores_cf_normalized, index=df_previsoes_svd.index, columns=df_previsoes_svd.columns)\n",
    "\n",
    "print(\"Scores do Collaborative Filtering (CF) calculados e normalizados.\")\n",
    "print(df_scores_cf_norm.round(2).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731600d",
   "metadata": {},
   "source": [
    "## 5. O Cérebro Híbrido: Combinar os Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e46df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A executar: O Cérebro Híbrido ---\n",
      "Scores Híbridos calculados (CB * 40% + CF * 60%).\n",
      "Provincia  Luanda  Benguela  Huíla  Namibe  Malanje  Cabinda  Huambo  \\\n",
      "user_id                                                                \n",
      "1            1.00      1.00   0.60    0.00     0.00     0.00    0.00   \n",
      "2            0.02      0.02   0.34    0.40     0.90     0.05    0.81   \n",
      "3            0.22      0.13   0.40    0.23     0.88     0.40    0.88   \n",
      "\n",
      "Provincia  Cuando Cubango  \n",
      "user_id                    \n",
      "1                    0.00  \n",
      "2                    1.00  \n",
      "3                    0.81  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- A executar: O Cérebro Híbrido ---\")\n",
    "\n",
    "# Criar um DataFrame final alinhado\n",
    "# (Usamos .reindex para garantir que ambos têm as mesmas colunas/linhas)\n",
    "users_finais = df_scores_cb_norm.index\n",
    "itens_finais = df_provincias_feat.index # Todas as 8 províncias\n",
    "\n",
    "# Alinhar CB (já tem todos os users e itens)\n",
    "cb_final = df_scores_cb_norm.reindex(index=users_finais, columns=itens_finais, fill_value=0)\n",
    "\n",
    "# Alinhar CF (só tem dados para 6 províncias e 3 users)\n",
    "cf_final = df_scores_cf_norm.reindex(index=users_finais, columns=itens_finais, fill_value=0)\n",
    "\n",
    "# A FÓRMULA HÍBRIDA\n",
    "df_scores_hibridos = (cb_final * W_CB) + (cf_final * W_CF)\n",
    "\n",
    "print(\"Scores Híbridos calculados (CB * 40% + CF * 60%).\")\n",
    "print(df_scores_hibridos.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb5d80",
   "metadata": {},
   "source": [
    "## 6. Gerar Recomendações Finais (Com Lógica \"Cold Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732adf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recomendações Finais (Híbrido) ---\n",
      "User 1: ['Luanda', 'Benguela', 'Huíla']\n",
      "User 2: ['Cuando Cubango', 'Malanje', 'Huambo']\n",
      "User 3: ['Huambo', 'Malanje', 'Cuando Cubango']\n"
     ]
    }
   ],
   "source": [
    "def get_hybrid_recommendations(user_id, k, df_hibrido, df_cb_norm):\n",
    "    \"\"\"\n",
    "    Gera recomendações híbridas.\n",
    "    Resolve o \"Cold Start\" (novo utilizador) usando apenas CB.\n",
    "    \"\"\"\n",
    "    if user_id not in df_hibrido.index:\n",
    "        # --- LÓGICA DE \"COLD START\" (NOVO UTILIZADOR) ---\n",
    "        # print(f\"User {user_id} é novo. A usar 100% Content-Based.\")\n",
    "        user_scores = df_cb_norm.loc[user_id]\n",
    "    else:\n",
    "        # --- LÓGICA HÍBRIDA (UTILIZADOR EXISTENTE) ---\n",
    "        user_scores = df_hibrido.loc[user_id]\n",
    "        \n",
    "    # Ordenar do maior para o menor e obter o Top-K\n",
    "    recs = user_scores.sort_values(ascending=False).index.tolist()\n",
    "    \n",
    "    # Remover itens que o utilizador JÁ AVALIOU (Opcional, mas boa prática)\n",
    "    # Vamos implementar isto para a defesa final:\n",
    "    # avaliados = []\n",
    "    # if user_id in df_matrix.index: # Verificar se o user tem historial\n",
    "    #    avaliados = df_matrix.loc[user_id][df_matrix.loc[user_id] > 0].index.tolist()\n",
    "        \n",
    "    #recs_sem_avaliados = [item for item in recs if item not in avaliados]\n",
    "    \n",
    "    return recs[:k]\n",
    "\n",
    "# Gerar recomendações finais para todos\n",
    "recomendacoes_finais = {}\n",
    "for user_id in df_users_feat.index: # Iterar por TODOS os utilizadores (incluindo novos)\n",
    "    recomendacoes_finais[user_id] = get_hybrid_recommendations(user_id, K, df_scores_hibridos, df_scores_cb_norm)\n",
    "\n",
    "print(\"\\n--- Recomendações Finais (Híbrido) ---\")\n",
    "for user, recs in recomendacoes_finais.items():\n",
    "    print(f\"User {user}: {recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8bf5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A calcular métricas finais para o Híbrido ---\n",
      "Recomendações Finais (Corrigidas):\n",
      "{1: ['Luanda', 'Benguela', 'Huíla'], 2: ['Cuando Cubango', 'Malanje', 'Huambo'], 3: ['Huambo', 'Malanje', 'Cuando Cubango']}\n",
      "\n",
      "--- Métricas de Relevância (Híbrido) ---\n",
      "Precisão@ 3 (Média): 66.67%\n",
      "Recall@ 3 (Média):   100.00%\n",
      "\n",
      "--- Métricas de Plataforma e Impacto (Híbrido) ---\n",
      "Diversidade@ 3 (% Emergentes):   77.78%\n",
      "Sustentabilidade@ 3 (% Sustentáveis): 55.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- A calcular métricas finais para o Híbrido ---\")\n",
    "\n",
    "# 1. Obter o \"Ground Truth\" (O que os utilizadores REALMENTE gostaram - ratings >= 4)\n",
    "ground_truth = {}\n",
    "for user in df_interactions['user_id'].unique():\n",
    "    user_likes = df_interactions[\n",
    "        (df_interactions['user_id'] == user) & (df_interactions['rating'] >= 4)\n",
    "    ]['provincia_visitada'].tolist()\n",
    "    ground_truth[user] = user_likes\n",
    "\n",
    "# 2. Corrigir a lógica de recomendação (como discutido)\n",
    "recomendacoes_finais_corrigidas = {}\n",
    "for user_id in df_users_feat.index:\n",
    "    \n",
    "    if user_id not in df_scores_hibridos.index:\n",
    "        # Lógica de \"Cold Start\" (não temos o User 3 no CF)\n",
    "        # Vamos usar o User 3 do CB como exemplo\n",
    "        if user_id == 3:\n",
    "            user_scores = df_scores_cb_norm.loc[user_id]\n",
    "        else:\n",
    "             user_scores = df_scores_cb_norm.loc[user_id] # Default\n",
    "    else:\n",
    "        # Lógica Híbrida\n",
    "        user_scores = df_scores_hibridos.loc[user_id]\n",
    "        \n",
    "    recs = user_scores.sort_values(ascending=False).index.tolist()\n",
    "    recomendacoes_finais_corrigidas[user_id] = recs[:K] # Top-K directo\n",
    "\n",
    "print(\"Recomendações Finais (Corrigidas):\")\n",
    "print(recomendacoes_finais_corrigidas)\n",
    "    \n",
    "# 3. Calcular Métricas de Relevância (Precisão, Recall)\n",
    "lista_precision = []\n",
    "lista_recall = []\n",
    "\n",
    "for user, likes in ground_truth.items():\n",
    "    if not likes or user not in recomendacoes_finais_corrigidas:\n",
    "        continue \n",
    "\n",
    "    recs_do_user = recomendacoes_finais_corrigidas[user]\n",
    "    hits = len(set(recs_do_user) & set(likes))\n",
    "    \n",
    "    precision_k = hits / K\n",
    "    lista_precision.append(precision_k)\n",
    "    \n",
    "    recall_k = hits / len(likes)\n",
    "    lista_recall.append(recall_k)\n",
    "\n",
    "print(\"\\n--- Métricas de Relevância (Híbrido) ---\")\n",
    "precision_final = np.mean(lista_precision)\n",
    "recall_final = np.mean(lista_recall)\n",
    "print(f\"Precisão@ {K} (Média): {precision_final * 100:.2f}%\")\n",
    "print(f\"Recall@ {K} (Média):   {recall_final * 100:.2f}%\")\n",
    "\n",
    "# 4. Calcular Métricas de Plataforma e Impacto\n",
    "mainstream_list = df_provincias_feat.sort_values(by='popularidade', ascending=False).index[:2].tolist()\n",
    "sustainable_list = df_provincias_feat[df_provincias_feat['impacto_ambiental'] >= 0.7].index.tolist()\n",
    "\n",
    "lista_diversidade = []\n",
    "lista_sustentabilidade = []\n",
    "\n",
    "for user, recs in recomendacoes_finais_corrigidas.items():\n",
    "    emergentes_recomendados = len(set(recs) - set(mainstream_list))\n",
    "    sustentaveis_recomendados = len(set(recs) & set(sustainable_list))\n",
    "    \n",
    "    lista_diversidade.append(emergentes_recomendados / K)\n",
    "    lista_sustentabilidade.append(sustentaveis_recomendados / K)\n",
    "\n",
    "print(\"\\n--- Métricas de Plataforma e Impacto (Híbrido) ---\")\n",
    "diversidade_final = np.mean(lista_diversidade)\n",
    "sustentabilidade_final = np.mean(lista_sustentabilidade)\n",
    "print(f\"Diversidade@ {K} (% Emergentes):   {diversidade_final * 100:.2f}%\")\n",
    "print(f\"Sustentabilidade@ {K} (% Sustentáveis): {sustentabilidade_final * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340dea0",
   "metadata": {},
   "source": [
    "## 6.1 Serielização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f36713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A guardar componentes do modelo em models/ ---\n",
      "svd_model.pkl (Modelo CF) guardado.\n",
      "cf_scaler.pkl (Scaler CF) guardado.\n",
      "cb_provincias_features.pkl (Features CB) guardado.\n",
      "cb_user_feature_names.pkl (Nomes das Features) guardado.\n",
      "interaction_matrix.pkl (Matriz de Interações) guardado.\n",
      "\n",
      "--- Serialização Completa. Pode avançar para o Deploy. ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Definir o diretório de destino\n",
    "OUTPUT_DIR = 'models' \n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) # Garantir que a pasta existe\n",
    "\n",
    "print(f\"\\n--- A guardar componentes do modelo em {OUTPUT_DIR}/ ---\")\n",
    "\n",
    "# 2. Guardar o modelo SVD treinado (Collaborative Filtering)\n",
    "# Variável: model (do TruncatedSVD)\n",
    "joblib.dump(model, os.path.join(OUTPUT_DIR, 'svd_model.pkl'))\n",
    "print(\"svd_model.pkl (Modelo CF) guardado.\")\n",
    "\n",
    "# 3. Guardar o scaler treinado para o CF (importante para a normalização)\n",
    "# Variável: scaler_cf (do MinMaxScaler)\n",
    "joblib.dump(scaler_cf, os.path.join(OUTPUT_DIR, 'cf_scaler.pkl'))\n",
    "print(\"cf_scaler.pkl (Scaler CF) guardado.\")\n",
    "\n",
    "# 4. Guardar as features das Províncias (Content-Based)\n",
    "# Variável: features_das_provincias (do Passo 3)\n",
    "joblib.dump(features_das_provincias, os.path.join(OUTPUT_DIR, 'cb_provincias_features.pkl'))\n",
    "print(\"cb_provincias_features.pkl (Features CB) guardado.\")\n",
    "\n",
    "# 5. Guardar os nomes das features do Utilizador (Para o CB saber a ordem)\n",
    "# Variável: features_dos_utilizadores.columns (do Passo 3)\n",
    "joblib.dump(features_dos_utilizadores.columns, os.path.join(OUTPUT_DIR, 'cb_user_feature_names.pkl'))\n",
    "print(\"cb_user_feature_names.pkl (Nomes das Features) guardado.\")\n",
    "\n",
    "# 6. Guardar a matriz de interações completa (Necessário para a lógica Híbrida/CF)\n",
    "# Variável: df_matrix (do Passo 4)\n",
    "joblib.dump(df_matrix, os.path.join(OUTPUT_DIR, 'interaction_matrix.pkl'))\n",
    "print(\"interaction_matrix.pkl (Matriz de Interações) guardado.\")\n",
    "\n",
    "print(\"\\n--- Serialização Completa. Pode avançar para o Deploy. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07220a75",
   "metadata": {},
   "source": [
    "## 7. Conclusões Finais: A Tabela de Comparação da Plataforma\n",
    "\n",
    "O nosso \"sprint\" de 4 notebooks pode ser resumido nesta tabela de comparação. Ela prova como cada modelo evoluiu, resolvendo as fraquezas do anterior.\n",
    "\n",
    "### Comparação Final de Métricas (K=3)\n",
    "\n",
    "| Métrica | 02_Baseline (Popularidade) | 03_Content-Based (Regras) | 04_CF (ML Puro / SVD) | 05_Hybrid (Final) |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| **`Precisão@3`** (Relevância) | 22.22% | 66.67% | 66.67% | **66.67%** |\n",
    "| **`Recall@3`** (Relevância) | 33.33% | 100.00% | 100.00% | **100.00%** |\n",
    "| **`Diversidade@3`** (Plataforma) | 33.33% | 77.78% | 77.78% | **77.78%** |\n",
    "| **`Sustentabilidade@3`** (Impacto)| 33.33% | **66.67%** | 55.56% | **55.56%** |\n",
    "\n",
    "\n",
    "\n",
    "### Análise da \"História\"\n",
    "\n",
    "1.  **Baseline vs. Modelos Inteligentes:** A tabela mostra um salto claro. Todos os nossos modelos inteligentes (CB, CF, Híbrido) **esmagaram** o Baseline em todas as métricas, provando que a personalização funciona. O `Recall@3` de 100% mostra que fomos capazes de recomendar *todos* os itens relevantes para os nossos utilizadores.\n",
    "\n",
    "2.  **A Fraqueza do \"ML Puro\" (CF):** O nosso modelo `04_CF (SVD)` foi poderoso, mas \"cego\". Ele foi o *pior* na métrica de `Sustentabilidade@3` (55.56%), porque ele só se preocupa com padrões de ratings, ignorando as metas de impacto.\n",
    "\n",
    "3.  **A \"Vitória\" do Híbrido:** O nosso `05_Hybrid_Model` final representa a solução de plataforma ideal.\n",
    "    * Ele mantém a **performance de relevância** perfeita (100% Recall) e **diversidade** (77.78%) dos outros modelos.\n",
    "    * Ele equilibra a `Sustentabilidade@3`. O \"boost\" de 40% do CB puxou a métrica de 33% (Baseline) para 55.56%. Embora não seja tão alto quanto o CB *puro* (66.67%), isto é um *trade-off* (troca) intencional: sacrificamos ligeiramente o impacto para ganhar o poder de \"descoberta\" (serendipidade) do SVD.\n",
    "    * Mais importante, o nosso Híbrido é **à prova de falhas**, usando 100% do CB para resolver o problema do \"Cold Start\", algo que o SVD sozinho não pode fazer.\n",
    "\n",
    "**Resultado Final:**\n",
    "Construímos uma arquitectura de ML defensável que equilibra de forma inteligente a **Satisfação do Utilizador** (aprendizagem do CF) com as **Metas da Plataforma** (regras do CB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7fbd4-e4c6-4a90-a5be-3c3d46b50592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
